       <!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <title>ì†Œë¦¬ ë¶„ì„ ì›¹ì•±</title>
  <style>
    body { font-family: sans-serif; max-width: 600px; margin: 20px auto; padding: 10px; }
    label, input, button { font-size: 1.2em; }
    .controls { display: flex; flex-direction: column; gap: 18px; margin-bottom: 24px; }
    button { padding: 10px 12px; border-radius: 5px; border: 1px solid #bbb; background: #f9f9f9; }
    .result { margin-top: 24px; font-size: 1.15em; }
  </style>
</head>
<body>
  <h2>ì†Œë¦¬ ë¶„ì„ (RPM ê¸°ë°˜)</h2>
  <div class="controls">
    <label>RPM ì…ë ¥: <input type="number" id="rpmInput" min="1" value="1800" style="width:90px"></label>
    <button id="micBtn">ë§ˆì´í¬ ì—°ê²°</button>
    <button id="startBtn">ë¶„ì„ ì‹œì‘</button>
    <button id="stopBtn">ë¶„ì„ ì¤‘ì§€</button>
  </div>
  <div class="result" id="result"></div>

  <script>
    let audioContext, analyser, source, mediaStream;
    let intervalId, startTime, allDiffs = [];
    let isAnalyzing = false;

    const rpmInput = document.getElementById('rpmInput');
    const micBtn = document.getElementById('micBtn');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const resultDiv = document.getElementById('result');

    // ì£¼íŒŒìˆ˜ Bin Index ê³„ì‚° í•¨ìˆ˜
    function freqToIndex(freq, sampleRate, fftSize) {
      return Math.round(freq / (sampleRate / fftSize));
    }

    // ë§ˆì´í¬ ì—°ê²°
    micBtn.onclick = async function() {
      if (audioContext) audioContext.close();
      audioContext = new (window.AudioContext || window.webkitAudioContext)();

      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({audio: true});
        source = audioContext.createMediaStreamSource(mediaStream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048;
        source.connect(analyser);
        resultDiv.textContent = "ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.";
      } catch (e) {
        resultDiv.textContent = "ë§ˆì´í¬ ì—°ê²° ì‹¤íŒ¨: " + e.message;
      }
    };

    // ë‹¨ì¼ ë¶„ì„ í•¨ìˆ˜
    function analyze(rpm) {
      const buffer = new Float32Array(analyser.frequencyBinCount);
      analyser.getFloatFrequencyData(buffer);
      const sampleRate = audioContext.sampleRate;
      const fftSize = analyser.fftSize;

      const baseFreq = rpm / 3;
      const peakFreq = baseFreq * 7;

      const baseIdx = freqToIndex(baseFreq, sampleRate, fftSize);
      const peakIdx = freqToIndex(peakFreq, sampleRate, fftSize);

      // ì£¼ë³€ê°’ í¬í•¨ í‰ê·  (Â±2)
      function avgAround(idx) {
        const range = 2, arr = [];
        for(let i=Math.max(0,idx-range); i<=Math.min(buffer.length-1,idx+range); ++i) arr.push(buffer[i]);
        return arr.reduce((a,b)=>a+b,0)/arr.length;
      }
      const avgBase = avgAround(baseIdx);
      const avgPeak = avgAround(peakIdx);

      return { avgBase, avgPeak, diff: avgPeak - avgBase };
    }

    // ë¶„ì„ ê³¼ì • ë¡œì§
    startBtn.onclick = function() {
      if (!analyser) { resultDiv.textContent = "ë¨¼ì € ë§ˆì´í¬ë¥¼ ì—°ê²°í•˜ì„¸ìš”."; return; }
      if (isAnalyzing) return;
      isAnalyzing = true;
      allDiffs = [];
      startTime = Date.now();
      resultDiv.textContent = "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.";
      const rpm = Number(rpmInput.value);

      // 20ì´ˆ ì£¼ê¸° ì¸¡ì • í•¨ìˆ˜
      function loop() {
        let cnt = 0;
        const measure = () => {
          const {avgBase, avgPeak, diff} = analyze(rpm);
          allDiffs.push(diff);
          resultDiv.innerHTML = `20ì´ˆ ì¸¡ì •:<br>í”¼í¬-ê¸°ë³¸ í‰ê· ì§„í­ì°¨: <b>${diff.toFixed(2)}</b>`;
          cnt++;
          if (isAnalyzing) intervalId = setTimeout(measure, 20000);
        };
        measure();
      }
      loop();
    };

    // ë¶„ì„ ì¤‘ì§€ ë° ì „ì²´ ê²°ê³¼ í‘œì‹œ
    stopBtn.onclick = function() {
      if (!isAnalyzing) return;
      isAnalyzing = false;
      clearTimeout(intervalId);
      if (allDiffs.length > 0) {
        const totalDiff = allDiffs.reduce((a,b)=>a+b,0)/allDiffs.length;
        const duration = ((Date.now() - startTime)/1000).toFixed(1);
        resultDiv.innerHTML = `
           ì „ì²´ ì¸¡ì • (${duration}ì´ˆ ë™ì•ˆ í‰ê· ):<br>
          í”¼í¬ì£¼íŒŒìˆ˜-ê¸°ë³¸ì£¼íŒŒìˆ˜ í‰ê· ì§„í­ ì°¨ì´: <b>${totalDiff.toFixed(2)}</b>
        `;
      } else {
        resultDiv.textContent = "ì¸¡ì •ëœ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.";
      }
    };
  </script>
</body>
</html>
        if (mediaStream) {
            mediaStream.getTracks().forEach(track => track.stop());
            // mediaStream = null; // ì—°ê²°ì„ ìœ ì§€í•  í•„ìš” ì—†ìŒ (ì¬ë¶„ì„ì‹œ ì¬ì—°ê²°)
        }
        if (mediaStreamSource) {
            mediaStreamSource.disconnect();
            // mediaStreamSource = null;
        }

        if (audioContext) { 
            const rpm = parseFloat(rpmInput.value);
            const F_fund = (rpm / 60) * 20;
            const F_peak = F_fund * 7;
            calculateAndDisplayResult(F_fund, F_peak, audioContext.currentTime, true); // ìµœì¢… êµ¬ê°„ ê³„ì‚°
        }
        
        // AudioContextëŠ” ì—°ê²° ë²„íŠ¼ì—ì„œ ì¬ê°œí•´ì•¼ í•˜ë¯€ë¡œ ë‹«ì§€ ì•ŠìŒ
        
        analyzeButton.disabled = false;
        stopButton.disabled = true;
        connectButton.disabled = true; // ë¶„ì„ ì •ì§€ í›„ì—ëŠ” ë‹¤ì‹œ ì—°ê²° ë²„íŠ¼ì„ í™œì„±í™”í•  í•„ìš” ì—†ìŒ (ì¬ë¶„ì„ ê°€ëŠ¥)
    }

    // --- 5. ì£¼íŒŒìˆ˜ ë²”ìœ„ ì§„í­ í‰ê·  ê³„ì‚° ë¡œì§ (ìƒëµ) ---
    function getAvgAmplitudeInRange(targetFrequency, dataArray, sampleRate, fftSize) {
        const range = targetFrequency * 0.03; 
        const lowerFreq = targetFrequency - range;
        const upperFreq = targetFrequency + range;
        const binResolution = sampleRate / fftSize;
        
        let startIndex = Math.floor(lowerFreq / binResolution);
        let endIndex = Math.ceil(upperFreq / binResolution);
        
        startIndex = Math.max(0, startIndex);
        endIndex = Math.min(dataArray.length - 1, endIndex);
        
        if (startIndex >= endIndex || endIndex >= dataArray.length) { return null; }
        
        let sumAmplitude = 0;
        let count = 0;
        for (let i = startIndex; i <= endIndex; i++) { 
            sumAmplitude += dataArray[i]; 
            count++; 
        }
        return sumAmplitude / count;
    }

    // --- 6. ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ ê³„ì‚° ë° ì—…ë°ì´íŠ¸ (NaN ë°©ì§€ ë¡œì§ í¬í•¨) ---
    function calculateAndDisplayResult(F_fund, F_peak, currentTime, isFinal = false) {
        
        const elapsedSinceStart = currentTime - analysisStartTime;
        
        let startSec;
        let endSec;

        if (isFinal) {
            // ì •ì§€ ì‹œ: ë§ˆì§€ë§‰ ë¦¬ì…‹ ì‹œì ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ì”ì—¬ êµ¬ê°„
            startSec = Math.floor(analysisStartTime); 
            if (startSec < FIRST_SEGMENT_START) startSec = FIRST_SEGMENT_START;
            endSec = Math.floor(currentTime);
        } else {
            // 20ì´ˆ ì£¼ê¸° ìë™ ë¶„ì„ ì‹œ: 
            const intervalNumber = Math.floor(elapsedSinceStart / INTERVAL_SEC);
            startSec = FIRST_SEGMENT_START + intervalNumber * INTERVAL_SEC; 
            endSec = startSec + INTERVAL_SEC;
        }

        const segmentDuration = endSec - startSec;
        
        let avgFund, avgPeak, difference, message = '';

        if (snapshotCount === 0) {
            // [NaN ë°©ì§€]: ë°ì´í„°ê°€ ì—†ì„ ë•Œ 0.00ìœ¼ë¡œ ì²˜ë¦¬
            avgFund = 0.00;
            avgPeak = 0.00;
            difference = 0.00;
            message = `[ê°ì§€ ì‹¤íŒ¨] ë°ì´í„° ë¶€ì¡±. ìœ íš¨ ì§„í­ ë¯¸ê°ì§€. (dB ê°’ 0ìœ¼ë¡œ ì²˜ë¦¬)`;

            if (isFinal && segmentDuration <= 2 && startSec > 0) { 
                statusDisplay.innerText = `ğŸ”´ ë¶„ì„ ì •ì§€ë¨. ìµœì¢… ${segmentDuration}ì´ˆ ì”ì—¬ êµ¬ê°„ì€ ì†ŒìŒ ê°ì§€ê°€ ì–´ë µê±°ë‚˜ ì§§ì•„ ê¸°ë¡ì„ ìƒëµí•©ë‹ˆë‹¤.`;
                
                // ë³€ìˆ˜ ë¦¬ì…‹
                cumulativeAmplitudeFund = 0;
                cumulativeAmplitudePeak = 0;
                snapshotCount = 0;
                analysisStartTime = currentTime;
                return;
            }
        } else {
            // ë°ì´í„°ê°€ ìˆì„ ê²½ìš° ì •ìƒ ê³„ì‚°
            avgFund = cumulativeAmplitudeFund / snapshotCount;
            avgPeak = cumulativeAmplitudePeak / snapshotCount;
            difference = parseFloat((avgPeak - avgFund).toFixed(2));
        }

        // ê²°ê³¼ HTML ìƒì„±
        const newEntry = document.createElement('div');
        newEntry.classList.add('result-entry');

        newEntry.innerHTML = `
            <p><strong>êµ¬ê°„:</strong> ${startSec}s ~ ${endSec}s ${isFinal ? '(ìµœì¢… í‰ê· )' : ''}</p>
            <p class="diff-result">ì§„í­ ì°¨ì´ (Peak - Fund) í‰ê· : <strong>${difference.toFixed(2)} dB</strong></p>
            <p><strong>ê¸°ë³¸ ì£¼íŒŒìˆ˜ (${F_fund.toFixed(2)} Hz):</strong> ${avgFund.toFixed(2)} dB</p>
            <p><strong>í”¼í¬ ì£¼íŒŒìˆ˜ (${F_peak.toFixed(2)} Hz):</strong> ${avgPeak.toFixed(2)} dB</p>
            ${snapshotCount === 0 ? `<p style="color: #ffab91; font-weight: bold;">${message}</p>` : ''}
        `;
        
        resultsContainer.insertBefore(newEntry, resultsContainer.children[1]); 
        
        // ë³€ìˆ˜ ë¦¬ì…‹
        cumulativeAmplitudeFund = 0;
        cumulativeAmplitudePeak = 0;
        snapshotCount = 0;
        analysisStartTime = currentTime;

        if (isFinal) {
             statusDisplay.innerText = "âœ… ë¶„ì„ ì¤‘ì§€ë¨. ìµœì¢… ê²°ê³¼ê°€ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.";
        } else if (snapshotCount === 0) {
             statusDisplay.innerText = `ğŸŸ¡ ë¶„ì„ ì¤‘... ${startSec}s ~ ${endSec}s êµ¬ê°„ ì†ŒìŒ ë¯¸ê°ì§€. (dB 0 ì²˜ë¦¬)`;
        }
    }

    // --- 7. ì‹¤ì‹œê°„ ë¶„ì„ ë£¨í”„ ---
    function realtimeAnalysisLoop(F_fund, F_peak) {
        if (!analyser || !audioContext || audioContext.state === 'closed') return;

        const dataArray = new Float32Array(analyser.frequencyBinCount);
        analyser.getFloatFrequencyData(dataArray);Â 

        const sampleRate = audioContext.sampleRate;
        const fftSize = analyser.fftSize;

        const currentAmpFund = getAvgAmplitudeInRange(F_fund, dataArray, sampleRate, fftSize);
        const currentAmpPeak = getAvgAmplitudeInRange(F_peak, dataArray, sampleRate, fftSize);

        if (currentAmpFund !== null && currentAmpPeak !== null) {
            cumulativeAmplitudeFund += currentAmpFund;
            cumulativeAmplitudePeak += currentAmpPeak;
            snapshotCount++;
        }

        const currentTime = audioContext.currentTime;
        const elapsedSinceStart = currentTime - analysisStartTime;

        // 20ì´ˆë§ˆë‹¤ ê²°ê³¼ ê³„ì‚° ë° ë¦¬ì…‹
        if (elapsedSinceStart >= INTERVAL_SEC) {
            calculateAndDisplayResult(F_fund, F_peak, currentTime, false);
        }

        analysisIntervalId = requestAnimationFrame(() => realtimeAnalysisLoop(F_fund, F_peak));
    }
</script>
</body>
</html> 
