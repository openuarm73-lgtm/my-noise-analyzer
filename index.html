<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>í ë¦¬íƒ€ì´ì € ë§ˆì´í¬ ì‹¤ì‹œê°„ ì†ŒìŒ ë¶„ì„</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; }
        .container { max-width: 700px; margin: 0 auto; border: 1px solid #ccc; padding: 20px; border-radius: 8px; }
        h2 { border-bottom: 2px solid #eee; padding-bottom: 10px; }
        input[type="number"], button { margin: 10px 0; padding: 10px; width: 100%; box-sizing: border-box; }
        #realtime-results { margin-top: 20px; padding: 15px; background-color: #f9f9f9; border-radius: 5px; }
        .label { font-weight: bold; }
        .result-entry { border-bottom: 1px dashed #ddd; padding-bottom: 10px; margin-bottom: 10px; }
        .result-entry:last-child { border-bottom: none; margin-bottom: 0; }
    </style>
</head>
<body>

<div class="container">
    <h2>ğŸ¤ í ë¦¬íƒ€ì´ì € ë§ˆì´í¬ ì‹¤ì‹œê°„ ì†ŒìŒ ë¶„ì„</h2>

    <p style="color: red;">**ì£¼ì˜:** ì´ ê¸°ëŠ¥ì€ HTTPS í™˜ê²½ì—ì„œë§Œ ì‘ë™í•˜ë©°, ë¸Œë¼ìš°ì €ê°€ ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì„ ìš”ì²­í•©ë‹ˆë‹¤.</p>
    
    <label class="label" for="rpm">1. RPM ì…ë ¥:</label>
    <input type="number" id="rpm" value="1200" placeholder="í ë¦¬íƒ€ì´ì € RPMì„ ì…ë ¥í•˜ì„¸ìš”" min="1">

    <button onclick="startMicrophoneAnalysis()" id="analyzeButton">2. ë§ˆì´í¬ ë…¹ìŒ ë° ë¶„ì„ ì‹œì‘</button>
    <button onclick="stopMicrophoneAnalysis()" id="stopButton" disabled>3. ë¶„ì„ ì¤‘ì§€</button>
    
    <p id="status-display" style="color: blue;">RPMì„ ì…ë ¥í•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.</p>

    <div id="realtime-results">
        <p class="label">30ì´ˆ êµ¬ê°„ë³„ ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼:</p>
    </div>
</div>

<script>
    // --- 1. ì „ì—­ ë³€ìˆ˜ ë° ì´ˆê¸°í™” ---
    let audioContext;
    let analyser;
    let mediaStreamSource = null;
    let mediaStream = null;
    let analysisIntervalId = null;

    // ëˆ„ì  ë³€ìˆ˜
    let snapshotCount = 0;
    let cumulativeAmplitudeFund = 0;
    let cumulativeAmplitudePeak = 0;
    let analysisStartTime = 0; // 30ì´ˆ ì£¼ê¸°ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•œ ì‹œì‘ ì‹œê°„

    const rpmInput = document.getElementById('rpm');
    const analyzeButton = document.getElementById('analyzeButton');
    const stopButton = document.getElementById('stopButton');
    const statusDisplay = document.getElementById('status-display');
    const realtimeResultsDiv = document.getElementById('realtime-results');

    // --- 2. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“ ë° ë¶„ì„ ì‹œì‘ ---
    async function startMicrophoneAnalysis() {
        const rpm = parseFloat(rpmInput.value);
        if (isNaN(rpm) || rpm <= 0) {
            alert('ìœ íš¨í•œ RPM ê°’ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.');
            return;
        }

        try {
            analyzeButton.disabled = true;
            statusDisplay.innerText = 'ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­ ì¤‘...';
            
            // AudioContext ì´ˆê¸°í™” (ì‚¬ìš©ì ìƒí˜¸ ì‘ìš© í›„ ìƒì„±)
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 4096;
            }

            // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“
            mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
            statusDisplay.innerText = 'ë§ˆì´í¬ ì—°ê²° ì„±ê³µ. ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.';

            // ë…¸ë“œ ìƒì„± ë° ì—°ê²°: ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ -> Analyser -> Destination (ì‹¤ì‹œê°„ìœ¼ë¡œ ì†Œë¦¬ê°€ ë“¤ë¦¼)
            mediaStreamSource = audioContext.createMediaStreamSource(mediaStream);
            mediaStreamSource.connect(analyser);
            mediaStreamSource.connect(audioContext.destination); 
            
            // ë¶„ì„ ì‹œì‘ ì „ ì´ˆê¸°í™”
            cumulativeAmplitudeFund = 0;
            cumulativeAmplitudePeak = 0;
            snapshotCount = 0;
            realtimeResultsDiv.innerHTML = '<p class="label">30ì´ˆ êµ¬ê°„ë³„ ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼:</p>';
            analysisStartTime = audioContext.currentTime;
            
            // ì£¼íŒŒìˆ˜ ê³„ì‚°
            const F_fund = (rpm / 60) * 20;
            const F_peak = F_fund * 7;

            // ì‹¤ì‹œê°„ ë¶„ì„ ë£¨í”„ ì‹œì‘
            realtimeAnalysisLoop(F_fund, F_peak);
            
            stopButton.disabled = false;

        } catch (error) {
            console.error('ë§ˆì´í¬ ì ‘ê·¼ ë˜ëŠ” ë¶„ì„ ì˜¤ë¥˜:', error);
            statusDisplay.innerText = `ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜: ${error.name}. HTTPS í™˜ê²½ì¸ì§€, ê¶Œí•œì„ í—ˆìš©í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.`;
            analyzeButton.disabled = false;
        }
    }

    // --- 3. ë¶„ì„ ì¤‘ì§€ í•¨ìˆ˜ ---
    function stopMicrophoneAnalysis() {
        if (analysisIntervalId) cancelAnimationFrame(analysisIntervalId);
        analysisIntervalId = null;
        
        // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ í•´ì œ
        if (mediaStream) {
            mediaStream.getTracks().forEach(track => track.stop());
            mediaStream = null;
        }
        
        // ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° í•´ì œ
        if (mediaStreamSource) {
            mediaStreamSource.disconnect();
            mediaStreamSource = null;
        }
        analyser.disconnect();

        // ë§ˆì§€ë§‰ ë‚¨ì€ êµ¬ê°„ ë°ì´í„° ì²˜ë¦¬
        if (snapshotCount > 0) {
            const rpm = parseFloat(rpmInput.value);
            const F_fund = (rpm / 60) * 20;
            const F_peak = F_fund * 7;
            calculateAndDisplayResult(F_fund, F_peak, audioContext.currentTime, true);
        }

        statusDisplay.innerText = "ë¶„ì„ ì¤‘ì§€ë¨.";
        analyzeButton.disabled = false;
        stopButton.disabled = true;
    }

    // --- 4. ì£¼íŒŒìˆ˜ ë²”ìœ„ ì§„í­ í‰ê·  ê³„ì‚° ë¡œì§ (ì´ì „ê³¼ ë™ì¼) ---
    function getAvgAmplitudeInRange(targetFrequency, dataArray, sampleRate, fftSize) {
        const range = targetFrequency * 0.03;
        const lowerFreq = targetFrequency - range;
        const upperFreq = targetFrequency + range;
        
        const binResolution = sampleRate / fftSize;
        
        let startIndex = Math.floor(lowerFreq / binResolution);
        let endIndex = Math.ceil(upperFreq / binResolution);
        
        startIndex = Math.max(0, startIndex);
        endIndex = Math.min(dataArray.length - 1, endIndex);
        
        if (startIndex >= endIndex || endIndex >= dataArray.length) {
            return null;
        }

        let sumAmplitude = 0;
        let count = 0;
        
        for (let i = startIndex; i <= endIndex; i++) {
            sumAmplitude += dataArray[i];
            count++;
        }

        return sumAmplitude / count;
    }

    // --- 5. ì‹¤ì‹œê°„ ë¶„ì„ ë£¨í”„ ë° ê²°ê³¼ ì—…ë°ì´íŠ¸ ---
    function calculateAndDisplayResult(F_fund, F_peak, currentTime, isFinal = false) {
        if (snapshotCount === 0) return;

        const avgFund = cumulativeAmplitudeFund / snapshotCount;
        const avgPeak = cumulativeAmplitudePeak / snapshotCount;
        const difference = avgPeak - avgFund;

        const endSec = Math.floor(currentTime);
        const startSec = isFinal ? Math.floor(analysisStartTime) : Math.floor(currentTime - 30); 

        const newEntry = document.createElement('div');
        newEntry.classList.add('result-entry');

        newEntry.innerHTML = `
            <p>--- <strong>[${startSec}s ~ ${endSec}s]</strong> ë¶„ì„ ê²°ê³¼ ${isFinal ? '(ìµœì¢… êµ¬ê°„)' : ''} ---</p>
            <p style="font-size: 1.2em; color: darkred;">ì§„í­ ì°¨ì´ (Peak - Fund): <strong>${difference.toFixed(2)} dB</strong></p>
            <p>ê¸°ë³¸ ì£¼íŒŒìˆ˜(${F_fund.toFixed(2)} Hz) í‰ê·  ì§„í­: ${avgFund.toFixed(2)} dB</p>
            <p>í”¼í¬ ì£¼íŒŒìˆ˜(${F_peak.toFixed(2)} Hz) í‰ê·  ì§„í­: ${avgPeak.toFixed(2)} dB</p>
        `;
        
        realtimeResultsDiv.prepend(newEntry);
        
        // ë³€ìˆ˜ ì´ˆê¸°í™” ë° ë‹¤ìŒ 30ì´ˆ êµ¬ê°„ ì‹œì‘
        cumulativeAmplitudeFund = 0;
        cumulativeAmplitudePeak = 0;
        snapshotCount = 0;
        analysisStartTime = currentTime;
    }

    function realtimeAnalysisLoop(F_fund, F_peak) {
        if (!analyser) return;

        const dataArray = new Float32Array(analyser.frequencyBinCount);
        analyser.getFloatFrequencyData(dataArray); 

        const sampleRate = audioContext.sampleRate;
        const fftSize = analyser.fftSize;

        // í˜„ì¬ ìŠ¤ëƒ…ìƒ· ì§„í­ ê³„ì‚°
        const currentAmpFund = getAvgAmplitudeInRange(F_fund, dataArray, sampleRate, fftSize);
        const currentAmpPeak = getAvgAmplitudeInRange(F_peak, dataArray, sampleRate, fftSize);

        if (currentAmpFund !== null && currentAmpPeak !== null) {
            cumulativeAmplitudeFund += currentAmpFund;
            cumulativeAmplitudePeak += currentAmpPeak;
            snapshotCount++;
        }

        const currentTime = audioContext.currentTime;
        const elapsedSinceStart = currentTime - analysisStartTime;

        // 30ì´ˆë§ˆë‹¤ ê²°ê³¼ ê³„ì‚° ë° ë¦¬ì…‹
        if (elapsedSinceStart >= 30) {
            calculateAndDisplayResult(F_fund, F_peak, currentTime, false);
        }

        // ë‹¤ìŒ í”„ë ˆì„ ì˜ˆì•½
        analysisIntervalId = requestAnimationFrame(() => realtimeAnalysisLoop(F_fund, F_peak));
    }
</script>
</body>
</html>